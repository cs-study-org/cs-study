# 5장 컴퓨터 아키텍처와 운영체제

<br>

## 목차
1. 컴퓨터 아키텍처란?
2. 폰노이만 구조 & 하버드 구조
3. CPU, Processor, Core
4. 캐시
5. 인터럽트
6. 상대주소 & 절대 주소
7. CPU 스케줄링
8. 스케줄링 알고리즘
9. 메모리 관리
10. 가상 메모리
11. 자료구조 (Stack , Queue, Tree)
12. 메모리 구조

<br>

* * *

<br>


## 컴퓨터 아키텍처란?

컴퓨터 에서의 하드웨어, 소프트웨어의 개별적인 기술뿐 아니라 <U>**컴퓨터 시스템 전체 에서의 종합적인 설계방식**</U>을 뜻한다.

<br>

* * *

<br>


## 폰노이만 구조 & 하버드 구조


**폰노이만 구조**

⇒ 폰 노이만의 가장 큰 업적은 현재와 같은 CPU, 메모리, 프로그램 구조를 갖는 범용 컴퓨터 **구조의 확립**

<img width="677" alt="폰노이만" src="https://user-images.githubusercontent.com/81874493/148178904-42c9de8b-0f7d-4fb1-a103-3a0da8163b53.png">

<br>

- 폰 노이만이 고안한 내장 메모리 순차처리 방식
    
    ⇒ 내장 메모리 순차 처리 방식이란?
    

    - 이전 컴퓨터는 명령을 수행하기 위해 하드웨어 전선을 매번 바꿔 끼워가며 명령을 입력해야 했다.
    - 폰 노이만 구조에서는 명령어( +, -, *, / 등)를 담은 소프트웨어가 메모리 안에 내장 되어 있어 필요시 마다 메모리 안의 소프트 웨어와 데이터를 CPU에 전달하여 처리하면 된다.
        
        ⇒ 여기서 메모리에 저장된 명령어를 받아와 계산할 때
        
        - 메모리로 부터 명령어 가져오기 - fetch
        - 명령어의 의미를 해석 - decode
        - 명령어를 실행 - excute
        - 명령 결과를 저장하는 - store
            
            ⇒ 위의 순서로 처리됨

            <br>
        
        ⇒ 폰노이만 구조는 위와 같은 ‘내장 메모리 순차 처리 방식’ 을 따른다.
        
        <br>
        
- 메모리 안에 프로그램과 데이터 영역은 물리적 구분이 없기 때문에 명령어와 데이터가 같은 메모리, 버스를 사용한다.
- 폰 노이만 구조는 ‘내장 메모리 순차 처리 방식’ 을 통해 하드웨어는 그대로 두고 소프트웨어(프로그램)만 교체하면 된다
    
    ⇒  편의성 증가 되었고 다양한 목적으로 사용이 가능하여 범용성이 향상
    
    <br>
    
- 단점
    
    단점으로는 <U>**병목 현상**</U>이 있다.
    
    병목 현상 :  “ 전체 시스템의 성능이나 용량이 하나의 구성요소로 인해 제한을 받는 현상을 의미한다”
    
    - 폰노이만 구조에서 CPU에서 빠르게 계산 처를 할 수 있어도 데이터를 불로오는 속도가 느리면 전체적으로 속도가 느려진다는 단점
        
        ⇒ 계산 속도가 빨라도 기억장치의 속도 영향을 받음
        
        ⇒ 즉 기억장치의 속도가 전체 시스템의 성능 저하를 야기한다.
        
<br>

* * *

<br>


## 하버드 구조

⇒ 폰노이만 구조의 병목 현상을 극복하기 위한 구조중 하나

<br>

<img width="685" alt="하버드" src="https://user-images.githubusercontent.com/81874493/148178936-a91b2b63-4901-4490-b0a0-ac84580e53e5.png">


- 병목 현상이 일어나는 근본적 원인
    
    ⇒ 프로그램 메모리와 데이터 메모리가 물리적 구분 없이 하나의 버스를 통해 CPU와 교류가 원인
    
    ⇒ 이로인해 CPU는 명령어와 데이터에 동시 접근 불가능
    
    ⇒ 나열된 명령을 한 번에 하나씩 읽고 쓰게 됨

    <br>
    
- 프로그램 메모리와 데이터 메모리의 구분
    
    ⇒ 하버드 구조에서는 CPU가 명령어와 데이터를 동시에 사용할 수 있도록 물리적으로 프로그램과 명령어영역을 물리적으로 구분
    
    ⇒ 이를 통해 현재 명령 처리를 끝냄과 동시에 다음 명령을 읽어 들일 수 있기때문에 폰노이만 구조 보다 더 빠른 속도를 낼 수 있다.
    
    <br>

- 단점
    - 이러한 속도를 높히기 위해 보다 많은 전기 회로를 필요로 한다.
    - 두개의 버스와 메모리를 가지게 되어 CPU 코어에 공간을 많이 차지 한다.
    

**현대**

<img width="677" alt="현재 구조" src="https://user-images.githubusercontent.com/81874493/148178959-20c18085-a28d-4451-8e9f-dee9d3209f31.png">

현대의 구조에는 

- CPU 외부적으로는 폰노이만 구조 적용
- CPU 내부적으로는 하버드 구조 적용
    
    ⇒ 속도 향상
    
- 그러나 이것 또한 폰노이만 구조를 기반으로 만들어진 것이기 때문에, **병목 현상**만 어느 정도 해결할 뿐 메모리 속의 프로그램을 순차적으로 실행하는 근본적인 구조 자체는 변하지 않았다.

<br>

* * *

<br>


## CPU, Processor, Core

<img width="688" alt="cpu processor" src="https://user-images.githubusercontent.com/81874493/148178976-1aae55db-6164-49fb-b60d-aee216329f0f.png">

**Processor**

우리가 흔히 말하는 프로세서(processor) 또는 CPU(Central Processor Unit)는 제어장치, 연산장치, 레지스터 그리고 데이터 버스로 구성된 디지털 시스템의 핵심 부분으로, 프로그램을 기억 장치로부터 읽어 연산 처리, 비교처리, 데이터 전송, 편집, 변환, 테스트와 분기 등의 데이터를 처리하고, 각종 장치를 구동하는 역할을 담당한다.

- 종류
    - CPU : 디바이스가 해야할 일을 총 지휘하는 프로세서
    - 보조프로세서(Coprocessor) : CPU의 기능을 보조하는 프로세서
    - 마이크로프로세서(Mircro Processor) : PC나 소형 디바이스에 장착된 프로세서
    
    <br>

- 구성 요소
    - Core : 프로세서의 핵심 연산 장치.
        - 제어장치(Control Unit) ; 소프트웨어를 읽고 하드웨어의 다른 부분으로 신호를 보냄
        - 연산장치(ALU, Arithmetic Logic Unit) : 덧셈, 뺄셈 등 사칙연산과 AND, OR와 같은 논리연산 등을 담당
        - 레지스터
        
        <br>

    - 내부 버스, 캐시(Cache) 등…
    

**Core**

CPU의 Core 즉 CPU의 핵심적인 역할을 수행해내는 중심부 역할을 말하며 이 코어에서 시스템의 모든 연산을 처리한다고 보면 된다.

 ⇒ CPU에서의 코어가 많은 경우 컴퓨터의 성능을 가장 좌우한다고 볼수도 있으며, 코어의 갯수가 늘어남에 따라 명칭은 다르게 사용된다.

<img width="712" alt="core" src="https://user-images.githubusercontent.com/81874493/148178993-658d231f-e533-4471-8613-87417dc2d0eb.png">

<br>

* * *

<br>

## 캐시

캐시란 CPU의 연산속도와 메모리에서 데이터를 가지고 오는 속도의 차이를 극복하기위해 사용되어 지는 CPU 내부의 데이터 임시 저장할 수 있는 고속 데이터스토리지 계층의 저장소 이다.

- CPU에 필요한 데이터를 미리 메모리에서 가져다 놓음 (prefetch)
- CPU 내부 버스 속도로 작동
- 사용이유
    - CPU가 메모리에서 순차적으로 데이터를 찾아 가져오는 속도를 줄이기위해 미리 캐시에 데이터를 미리 가져다 놓고 캐시에서 찾아 보는 것
        - 캐시에서 원하는 데이터를 찾았을 때 : Cache hit
        - 캐시에서 원하는 데이터를 못 찾았을 때: Cache miss
            
            ⇒ 캐시 히트가 되는 비율을 캐시 적중률 이라고 한다.
            
            ⇒ 일반적 컴퓨터 캐시 적중률 90%

<br>

* * *

<br>


## 인터럽트(Interrupt)

인터럽트는 란 마이크로프로세서(CPU)가 프로그램을 실행하고 있을 때, 입출력 하드웨어 등의 장치에 예외상황이 발생하여 처리가 필요할 경우에 마이크로 프로세서에게 알려 처리하고 다시 실행중인 작업으로 복귀 할 수 있도록 하는 것을 의미한다.

>⇒ 인터럽트가 있기 전 과거에는 입출력 장치가 거의 없어 입출력을 요청하면 운영체제가 주기적으로 입출력 장치를 직접 확인해서 처리 == 이러한 방법을 **“폴링 방식”** 이라고 한다.

<br>

- 인터럽트의 분류
    - 동기적 인터럽트

        - 실행 중인 명령어로 인해 발생하는 인터럽트
            - 프로그램상 문제 때문에 발생하는 인터럽트( 외부 사용자의 메모리 접근, 오버플로나 언더플로)
            - 컴퓨터 작업자가 의도적으로 프로세스를 중단하기 위해 발생시킨 인터럽트
            - 입출력 장치 같은 주변 장치의 조작에 의한 인터럽트
            - 산술 연산 중 발생하는 인터럽트( 어떤수를 0으로 나눔 )
            
            <br>

        - 실행 중인 명령어와 무관하게 발생하는 비동기적 인터럽트
            - 하드디스크 읽기 오류
            - 메모리 불량 등
                
                ⇒ 하드웨어적 오류로 발생하는 인터럽트로 ( 사용자의 키보드 마우스 인터럽트 등이 있다.)
                
                <br>
- 인터럽트 벡터
    
    <img width="668" alt="interrupt vector" src="https://user-images.githubusercontent.com/81874493/148179031-0c42f8db-621b-4e98-9737-22a16d1dbe82.png">

    - 시스템에는 많은 인터럽트가 존재하고 각 인터럽트는 한번에 한나씩 발생하는 것이 아니라 한순간 여러개가 동시에 발생하기도 한다.
        
        ⇒ 이렇게 동시에 발생하는 인터럽트를 하나로 묶어서 처리하는 개념이 인터럽트 벡터 이다.
        
        <br>

- 인터럽트 처리 과정
    - 인터럽트 벡터는 인터럽트의 집합으로 각 번호의 매칭되는 시스템에서 인터럽트가 발생하면 인터럽트 벡터의 번호가 0 에서 1 로 바뀐다.
    
    <br>

    - 인터럽트 벡터에는 각 인터럽트를 처리하는 함수가 연결되어 있어 인터럽트가 발생하면 이 함수를 통해 처리하게 되는데 이 함수를 인터럽트 핸들러 라고 한다.( 사용자 재정의 가능)
    
    <br>

    - 인터럽트 처리과정
        1. 인터럽트 발생
        2. 현재 실행 중인 프로세스 일시 정지, 재시작하기 위한 프로세스 관련 정보를 임시 저장
        3. 인터럽트 컨트롤러가 실행되어 인터럽트의 처리 순서를 결정
            
            ⇒ 인터럽트가 동시에 발생경우 우선순위를 통해 처리 순서를 결정하는것
            
        4. 먼저 처리할 인터럽트가 결정되면 벡터에 등록된 인터럽트 핸들러가 실행된다.
        5. 인터럽트 벡터에 연결된 핸들러가 인터럽트 처리를 마치면 일시 정지된 프로세스가 다시 실행되거나 종료된다.
            
            ⇒ 발생 인터럽트가 입출력 완료 같은 경우 다시 프로세스 실행
            
            ⇒ 발생 인터럽트가 메모리 침범과 같은 오류이면 종료된다.

<br>

* * *

<br>

## 상대주소 & 절대 주소

- 메모리 영역의 구분
    
    <img width="685" alt="절대 주소 상대 주소" src="https://user-images.githubusercontent.com/81874493/148179061-f1cc974a-d4a9-489b-a9ee-d9b8260f64d8.png">

    - 메모리 관리 장치 (MMU) 는 메모리를 운영체제와 사용자 영역으로 나누어 관리한다.
        - 운영체제 영역 : 운영체제 시스템에서 사용하는 메모리 영역
        - 사용자 영역 : 사용자 프로세스에서 사용하는 메모리 영역
            
            ⇒ 운영체제는 시스템 관리하는 중요한 역할을 하기 때문에 사용자가 운영체제를 침범하지 못하도록 분리하여 사용한다.
            
            ⇒사용자 영역이 운영체제 영역을 침범하지 못하도록 막기 위해서는 하드웨어가 필요하다.
            
            ⇒ 여기서 사용되어지는 하드웨어가 CPU 내부의 “경계 레지스터” 이다.
            
            ⇒ 메모리 관리자는 사용자가 작업을 요청할 때마다 경계 레지스터의 값을 벗어나는지 검사하고 벗어난다면 그 프로세스를 종료한다.
            
            <br>

- 절대 주소와 상대 주소의 개념
    - 절대 주소
        - 실제 물리 주소를 가리키는 절대 주소
        - 메모리 관리 장치 입장에서 바라본 주소
        - 메모리 주소 레지스터(MAR) 이 사용하는 주소로 컴퓨터에 꽂힌 메모리의 실제 주소를 의미
        
        <br>

    - 상대 주소
        - 사용자 영역이 시작되는 번지를 0 으로 변경하여 사용하는 주소
        - 상대주소는 사용자 입장에서 바라본 주소
        - 절대 주소와 상관없이 0 번지 부터 시작된다.
        
            >⇒ 상대 주소를 사용하면 프로세스 입장에서 상대 주소가 사용할 수 없는 영역의 위치를 알필요가 없으며 주소가 항상 0 번지 부터 시작하기 때문에 편리하다. 
        
        | 구분 | 절대 주소 | 상대 주소 |
        | --- | --- | --- |
        | 관점 | 메모리 관리자 입장 | 사용자 프로세스 입장 |
        | 주소 시작 | 물리 주소 0 번지 부터 시작 | 물리 주소와 관계없이 항상 0 번지 부터 시작 |
        | 주소 공간 | 물리 주소(실제 주소) 공간 | 논리 주소 공간 |

    <br>

- 상대주소를 절대 주소로 변환 ( 메모리 관리 장치 관점 메모리를 구분하고 CPU 명령을 통한 메모리 접근 시)
    
    ⇒ 메모리 접근시 상대 주소를 사용하면 상대 주소를 실제 메모리 내의 물리 주소, 즉 절대 주소로 변환하여야 한다.
    
    - 변환 과정
        1. 사용자 프로세스가 상대 주소를 통해 메모리에 접근
        2. 메모리 관리 장치가 상대 주소값에 재배치 레지스터 값을 더하여 절대 주소를 구하여 메모리에 접근 
            
            ( MMU 를 통해서 접근한다. )
            
        
        *재배치 레지스터
        
        ⇒ 주소 변환의 기본이 되는 주소값을 가진 레지스터로, 메모리에서 사용자 영역의 시작 주소값이 저장된다.
        
<br>

* * *

<br>

## CPU 스케줄링(Scheduling)

CPU 스케줄러는 프로세스가 생성되고 종료 될 때까지 모든 상태 변화를 조정하는 일을 한다.

⇒  CPU 스케줄러는 여러 스케줄링 방식을 통해 프로세스의 상황을 고려하고 CPU와 시스템 자원을 어떻게 배정할지의 결정하는 일을 한다. 

- 스케줄링의 단계
    
    <img width="672" alt="스케줄링 단계" src="https://user-images.githubusercontent.com/81874493/148179082-f1d69901-334b-40eb-90b5-b5d51590f57a.png">

    - 고수준 스케줄링
        - 고수준 스케줄링에서의 작업의 단위는 운영체제에서 다루는 일의 가장 큰단위 이며, 1개 또는 여러 개의 프로세스로 이루어진다.
        - 고수준 스케줄링은 시스템 내의 전체 작업 수를 조절하는 것을 지칭한다.
            
            ⇒고수준 스케줄링 단계에서는 어떤 작업을 시스템이 받아들일지(프로세스 생성) 또는 거부 할지를 결정한다.
            
            ⇒ 고수준 스케줄링에 따라 시스템에서 동시에 실행 가능한 프로세스의 총 개수가 결정된다.

        <br>        
    
    - 중간 수준 스케줄링
        - 고수준 과 저수준 스케줄링 사이에 일어나는 스케줄링
        - 중간 수준 스케줄링은 중지와 활성화로 전체 시스템의 활성화된 프로세스 수를 조절하여 과부하를 막는 역할을 한다.
            
            ⇒ 일부 프로세스를 중지 상태로 옮겨 나머지 프로세스가 원만하게 작동하도록 지원한다.
            
        - 저수준 스케줄링이 원만하게 이루어지도록 완충하는 역할을 한다.
    
    <br>

    - 저수준 스케줄링
        - 저수준 스케줄링은 프로세스 상태에 관한 내용의 대부분을 처리한다.
            - 준비 상태에 있는 프로세스 중 하나를 골라 실행 상태로 보냄( 프로세스에 cpu 할당)
            - 실행 상태에 있는 프로세스를 대기 상태로 보냄
            - 대기 상태를 준비 상태로 보냄
        
        <br>

- 스케줄링의 목적
    - 공평성 : 모든 프로세스가 자원을 공평하게 배정받아야 하며, 자원 배정 과정에서 특정 프로세스가 배제 되어서는 안된다.

    <br>

    - 효율성 : 시스템 자원이 유휴 시간 없이 사용 되도록 스케줄링을 하고, 유휴 자원을 사용하려는 프로세스에는 우선권을 주어야 한다.

    <br>

    - 안정성 : 우선순위를 사용하여 중요 프로세스가 먼저 작동하도록 배정하여 시스템 자원을 점유하거나 파괴하려는 프로세스로부터 자원을 보호해야 한다.
    
    <br>

    - 확장성 : 프로세스가 증가해도 시스템이 안정적으로 작동하도록 조치해야한다. 또한 시스템 자원이 늘어나는 경우 이 혜택이 시스템에 반영되게 해야한다.

    <br>

    - 반응 시간 보장 : 응답이 없는 경우 사용자는 시스템이 멈춘 것으로 가정하기 때문에 시스템은 저절한 시간 안에 프로세스의 요구에 반응 해야 한다.

    <br>

    - 무한 연기 방지 : 특정 프로세스의 작업이 무한히 연기 되어서는 안된다.
    
    <br>

- 스케줄링의 고려 사항
    
    ⇒ CPU 스케줄러가 어떤 프로세스에 우선적으로 CPU를 할당 할지 결정할 때 고려해야할 사항들이 있다.
    
    - 선점형 스케줄링 : 어떤 프로세스가 CPU를 할당 받아 실행 중이더라도 운영체제가 CPU를 강제로 빼앗을 수 있는 스케줄링 방식
        
        ⇒ 선점형 스케줄링은 운영체제가 필요하다고 판단하면 실행 상태에 있는 프로세스의 작업을 중단하고 새로운 작업을 시작할 수 있다.
        
        - 대표적인 예) 인터럽트 처리
            - 인터럽트 발생시 현재 실행 작업 중단하고 커널을 깨워 인터럽트 처리 시키고 인터럽트 처리 완료시 원래 작업으로 돌아간다.
        - 단점
            - 문맥 교환 같은 부가적 작업으로 인해 낭비가 생기는 단점이 있다.
        - 장점
            - 하나의 프로세스가 CPU를 독점할 수 없기 때문에 빠른 응답 시간을 요구하는
                - 대화형 시스템
                - 시분할 시스템
                
                ⇒ 에 적합하다.
                
    
    - 비선점형 스케줄링 : 어떤 프로세스가 CPU를 점유하면 다른 프로세스가 이를 빼앗을 수 없는 스케줄링 방식이다.
        
        ⇒ 어떤 프로세스가 실행 상태에 들어가 CPU를 사용하면 그 프로세스가 종료되거나 자발적 대기 상태에들어가기 전까지는 계속 실행된다.
        
        - 단점
            - CPU 사용 시간이 긴 프로세스 때문에 CPU 사용 시간이 짧은 여러 프로세스가 오랫동안 기다리게되어 전체 시스템의 처리율이 떨어진다.
        - 장점
            - 선점형 스케줄링 보다 스케줄러의 작업량이 적고 문맥교환에 의한 낭비도 적다.
        
        ⇒  과거 일괄 작업 시스템 에서 사용하던 방식이다.
        
        ( 초기 운영체제의 형태로 여러개의 작업을 단일 작업으로 묶어서 일괄 처리하는 시스템으로 작업을 실행하면 끝날때까지 아무것도 못함)
        
        <br>
    
    정리)
    
    | 구분 | 선점형 | 비선점형 |
    | --- | --- | --- |
    | 작업방식 | 실행 상태에 있는 작업을 중단시키고 새로운 작업 실행 가능 | 실행 상태에 있는 작업이 완료될 때까지 다른 작업이 불가능 |
    | 장점 | 프로세스가 CPU를 독점할 수 없어 대화형이나 시분할 시스템에 적합 | CPU 스케줄러의 작업량이 적고 문맥교환의 오버헤드가 적다 |
    | 단점 | 문맥 교환이 자주 발생 | 기다리는 프로세스가 많아 처리율이 떨어진다. |
    | 사용 | 시불할 방식 스케줄러에 사용 | 일괄 처리 방식 스케줄러에 사용된다. |
    | 중요도 | 높 | 낮 |

<br>

* * *

<br>

## 스케줄링 알고리즘 (Scheduling algorithm)

- FCFS(First Come First Serve) 스케줄링
    - 준비큐에 도착한 순서대로 CPU를 할당하는 방식
    - 비 선점형 방식
    - 모든 프로세스는 우선순위가 동일
    - 평가
        - 처리시간이 긴 프로세스가 CPU를 차지하면 다른 프로세스들은 하염없이 기다려 시스템의 효율성이 떨어지는 문제가 일어난다 == 콘보이 효과(Convoy edffect)

    <br>

- SJF(Shortest Job First)
    - 준비큐의 실행시간이 가장 짧은 작업 부터 CPU를 할당하는 방식
    - 비 선점형 방식
    - 콘 보이 효과 완화
    - 평가
        - 운영체제가 프로세스 종료시간을 정확히 예측하기 어렵다.
        - 실행시간이 짧은 작업부터 계속 CPU를 할당하면 긴 작업은 끝없이 기다려야 하기에 공평성이 떨어진다 == 아사현상(starvation)
            - 아사 현상은 에이징(aging)[ 프로세스가 양보할 수 있는 상한선을 정하는 방식] 을 통해 완화 할 수 있다.

    <br>

- HRN(Highest Response Ratio Next)
    - 서비스를 받기 위해 기다린 시간과 CPU 사용 시간을 고려하여 우선순위를 결정하여 CPU 할당하는 방식
    - 비 선점형 방식
    - 아사 현상 완화
    - 우선순위 = (대기 시간 + CPU 사용시간)/ CPU사용시간
    - 평가
        - 여전히 공평성 위배로 많이 사용되지 않는다.
        
        <br>

- 라운드 로빈 (Round Robin)
    - 프로세스가 할당 받은 시간(타임 슬라이스) 동안 작업하다가 작업을 완료하지 못하면 준비큐의 맨뒤로 가서 다시 자신의 차례를 기다리는 방식
    - 선점형 알고리즘
    - 평가
        - 라운드 로빈 스케줄링이 효과적으로 작동하기 위해 문맥교환에 따른 추가시간을 고려하여 타임 슬라이스를 적절히 설정해야 한다.
        - 타임슬라이스
            - 크게 설정할 경우 ⇒ 하나의 작업이 끝난 뒤 다음 작업이 시작되는 FCFS방식과 동일해짐
            - 작게 설정한 경우 ⇒ 문맥교환이 자주 일어나 서비스 시간보다 문맥 교환에 많은 시간을 낭비하게 된다.

    <br>

- SRT(Shortest Remaining Time)
    - SJF + Round Robin 혼합 방식
    - 기본 라운드 방식을 사용하되 CPU 할당 받을 프로세스를 선택시 작업 시간이 가장 적은 프로세스를 선택하여 서비스 한다.
    - 선점형 방식
    - 평가
        - 현재 실행 중인 프로세스왕 큐에 있는 프로세스의 남은 시간을 주기적 계산해야한다.
        - 남은 시간이 더 적은 프로세스와 문맥교환 해야한다.
        - 운영체제가 프로세스 종료시간을 예측하기 어렵다.
        - 아사 현상이 일어난다.

    <br>

- 우선순위 스케줄링
    - 프로세스는 중요도에 따라 우선순위를 갖는데 이러한 우선순위를 반영한 스케줄링이 우선순위 스케줄링 알고리즘이다.
    - 우선순위는 비선점형 선점형 방식 모두 적용할 수 있다.
    - 분류
        - 고정 우선순위 알고리즘 : 한번 우선순위를 부여 받으면 종료시까지 우선순위가 고정된다
            
            ⇒ 단순 구현 가능, 시스템의 상황을 반영하지 못해 효율성은 떨어짐
            
        - 변동 우선순위 알고리즘 : 일정 시간마다 우선순위가 변한다.
            
            ⇒ 우선순위를 새로 계산하고 반영하기에 시스템이 복잡, 시스템 상황 반영 가능하여 효율성을 높힐 수 있다.
            
    - 평가
        - 우선순위가 높은 프로세스에 먼저 CPU 할당 → 공평성 위배, 아사현상
        - 준비큐의 프로세스 순서 무시하고 프로세스의 우선순위를 매번 변경해야 하기 때문에 오버헤드가 발생 → 효율성 떨어짐
        
        ⇒ 하지만 커널 프로세스가 일반 프로세스보다 우선 서비스될 수 없기 때문에 우선순위는 시스템의 효율성 보다 프로세스의 중요도에 따라 결정되는 것
        
    <br>

- 다단계 큐 스케줄링
    - 다단계 큐 스케줄링은 우선순위에 따라 준비 큐를 여러개 사용하는 방식
        
        ⇒ 프로세스는 운영체제로 부터 부여받은 우선순위에 따라 우선순위 큐에 삽입된다.
        
    - 고정형 우선순위를 사용
    - 선점형 방식
    - 우선순위가 더 높은 상단의 큐에 있는 모든 프로세스의 작업이 끝나야 다음 큐 작업이 시작
    - 각 큐 작업은 라운드 로빈 방식을 사용
    - 평가
        - 우선순위가 낮은 프로세스의 작업이 연기되는 아사현상
            
            ⇒ 이를 완화하기위해 제안된것이 다단계 피드백 큐 스케줄링
            
        <br>

- 다단계 피드백 큐 스케줄링
    
    <img width="578" alt="다단계 피드백 큐" src="https://user-images.githubusercontent.com/81874493/148179110-bc6f498a-0036-4385-b9d4-90b5c6540fa9.png">

    - 우선순위에 따라 준비큐를 여러개 사용하는 방식
    - 각 큐의 서비스 단계에서는 CPU 할당받아 실행될때 마다 프로세스의 우선순위를 낮추어 낮은 프로세스의 실행이 연기되는 문제를 완화
    - 우선순위가 낮아질수록 해당 큐의 타임 슬라이스가 커짐
    - 마지막 큐는 FCFS 방식 스케줄링으로 동작
    - 평가
        - 아사 현상이 일어날 수 있음 → 에이징 방식을 사용하여 완화 가능

 
<br>

* * *

<br>       

## 메모리의 관리

프로세스별 크기가 다  다르기 때문에 메모리를 어떻게 나누어 사용할 것인지가 중요 개념이다.

- 메모리 분할 방식
    - 가변 분할 방식 : 프로세스 크기에 따라 메모리를 나눔
        - 장점 : 프로세스를 한 덩어리로 처리하여 하나의 프로세스를 연속된 메모리 공간에 배치
        - 단점
            - 사용하고 남은 공간을 하나로 합쳐야 하며, 사용되는 메모리 공간에 이와 함께 메모리 공간에 움직임이 있다.
            - 메모리 통합 등 부작적인 작업이 필요하여 메모리 관리가 복잡하다.
            
            <br>

    - 고정 분할 방식 : 프로세스 크기와 상관없이 고정 크기로 메모리를 나눔
        - 장점 : 메모리를 일정한 크기로 나누어 관리하기 때문에 상대적 관리가 수월하다.
        - 단점
            - 쓸모 없는 공간으로 인해 메모리가의 낭비가 발생한다.
        
        ⇒ 현대 운영체제에서 메모리 관리는 기본 고정분할 방식을 사용하며 일부분은 가변 분할 방식을 혼합하여 사용하고 있다.
        
        <br>

    정리)
    
    | 구분 | 가변 분할 방식 | 고정 분할 방식 |
    | --- | --- | --- |
    | 메모리 단위 | 세그먼테이션 | 페이징 |
    | 특징 | 연속 메모리 할당 | 비연속 메모 할당 |
    | 장점 | 프로세스를 한 덩어리로 관리 | 메모리 관리가 편리 |
    | 단점 | 빈 공간의 관리가 어려움 | 프로세스가 분할되어 처리 |
    | 단편화 | 외부 단편화 | 내부 단편화 |
    - 단편화 : 메모리 사이 사용되지 못하는 작은 조각들
        - 외부 단편화 : 메모리가 빈틈없이 사용되고 나머지 공간이 비는 것
        - 내부 단편화 : 메모리가 고정 크기로 구분되어 한 공간에 프로세스가 들어갔을때 나머지 공간


<br>

* * *

<br>

## 가상 메모리

가상 메모리란 크기가 다른 물리 메모리에서 일관되게 프로세스를 실행 시킬 수 있는 기술이다.

- 개념
    
    메모리의 크기는 컴퓨터 마다 다른데 운영체제가 물리 메모리의 크기에만 의존한다면 메모리 크기마다 실행 가능하고 불가능한 프로그램이 될 수 있다.
    
    ⇒ 이렇게 된다면 프로그래머는 메모리 크기에 맞는 프로그램만을 개발 해야 한다.
    
    ⇒ 실제 메모리 크기를 고려하여 프로그래밍하기는 매우 어렵다.
    
    <br>

    현대 메모리 관리의 가장 큰 특징은 물리 메모리의 크기와 프로세스가 올라갈 메모리의 위치를 신경 쓰지 않고 프로그래밍하도록 지원하는 것
    
    **가상 메모리** : 물리 메모리의 크기와 상관없이 프로세스에 커다란 메모리 공간을 제공하는 기술
    
    ⇒ 이를 통해 운영체제가 메모리에 어디에 위치하는지, 물리 메모리의 크기가 어느 정도인지 신경 쓰지 않고 메모리를 마음대로 사용 가능하다.

    <br>
    
- 가상 메모리의 크기
    
    가상 메모리 개념이 가능하도록 하는 주요 개념은 스왑영역 이다.
    
    - 스왑영역
        
        스왑영역은 하드디스크에 존재하지만 메모리 관리자가 관리하는 영역이다.
        
    - 스왑
        - 스왑은 메모리가 모자라 임시 저장되는 특별한 공간
            - 스왑 인 = 스왑 영역에서 메모리로 데이터를 가져오는 작업
            - 스왑 아웃 = 메모리에서 스왑영역으로 데이터를 보내는 작업
            
            <br>

    ⇒ 가상 메모리의 크기 = 메모리 관리자가 사용할 수 있는 메모리의 전체 크기 
    
    =[ 물리 메모리 크기 + 스왑영역 크기]
    
    <br>
    
- 가상 메모리의 분할 방식
    
    메모리 방식은 가변 분할 방식과 고정 분할 방식으로 나뉘는 것 처럼
    
    ⇒ 가상 메모리도 두가지로 분류 된다.
    
    - 가변 분할 방식을 이용한 세그먼테이션 관리 기법
    - 고정 분할 방식을 이용한 페이징 관리 기법
    
    <br>

    | 구분 | 가상 메모리 | 물리 메모리 |
    | --- | --- | --- |
    | 최대 메모리 크기 | CPU 비트 값 의존 | CPU 비트 값 의존 |
    | 메모리 분할 방식 | -세그먼 테이션
    -페이징
    -세그먼 테이션 페이징 혼용 기법 | -가변 분할 방식
    -고정 분할 방식 |
    | 주소 지정 방식 | 가상 주소 | 절대 주소, 상대 주소 |


<br>


<br>

## 자료 구조 ( Stack, Queue, Tree)

**스택(Stack)..(선형 자료구조)**

<img width="639" alt="스택" src="https://user-images.githubusercontent.com/81874493/148179154-9584c82b-c854-48ec-98b7-9c2920602859.png">

⇒ 스택은 컴퓨터의 기본 자료구조 중 하나로 한쪽 끝에서만 자료를 넣거나 뺄 수 있는 LIFO 형식의 자료 구조

- 가장 최근에 들어온 자료가 가장 먼저 나가게 되는 ***LIFO(Last-In First-Out)*** 형태를 갖는다.
- 스택의 입출력은 맨 위에서만 일어나기 때문에 스택의 **중간에서는 데이터를 삭제하는 것이 *불가능***
- 스택이 입출력이 이루어지는 부분을 *스택 상단(Stack top)* , 바닥 부분을 *스택 하단(Stack bottom)* , 스택에 저장되는 것을 *요소(Element)* 라 부르며 스택에 요소가 하나도 없을 때 그러한 스택을 *공백 스택(Empty stack)* 이라고 합니다.
- 택에 요소를 *삽입하는 연산* 을 **Push** , *삭제 연산* 을 **Pop** 이라고 한다.
- 사용 사례
    - 재귀 알고리즘을 반복문을 통해서 구현
    - 실행 취소 (undo)
    - 웹 브라우저 뒤로가기
    - 문자열의 역순 출력 등

<br>


<br>

**큐(QUEUE) ..(선형 자료구조)**

[큐 이미지]

⇒ 큐란 컴퓨터의 기본 자료구조 중 하나로 먼저 들어온 데이터가 먼저 나가는 구조로 되어 있는 자료구조 이다.

- 가장 최근 들어온 자료가 가장 먼저 나가는 *FIFO(First-In First-Out) 선입선출 형태를 갖는다.*
- 큐는 한쪽에서는 데이터가 추가되고 한쪽에서는 데이터가 삭제되는 구조를 가지고 있다.
- 큐에서 **삽입(Enqueue)** 이 일어나는 곳을 **Rear** 라고 하며 **삭제(Dequeue)** 가 일어나는 곳을 **Front** 라고 한다.

<img width="692" alt="큐" src="https://user-images.githubusercontent.com/81874493/148179170-ffacf174-3903-49d0-9f4d-223fa9ffd80a.png">

- 큐의 종류
    - Linear Queue(선형 **큐**)
    - Circular Queue (원형 **큐**)
    - Priority Queue(우선순위 **큐**)
        
        ⇒ 들어간 순서에 상관 없이 우선순위가 높은 데이터가 먼저 나오는 큐
        
        ⇒ heap이라는 자료구조를 가지고 구현할 수 있다.
        
        <br>
        
- 사용
    - 캐시(Cache) 구현
    - 우선순위가 같은 작업 예약 (인쇄 대기열)
    - 선입선출이 필요한 대기열 (티켓 카운터)
    - 프린터의 출력 처리 등

<br>


<br>

**트리(Tree) .. (비선형 자료구조)**

<img width="700" alt="트리" src="https://user-images.githubusercontent.com/81874493/148179187-2c9b3820-58c9-44f1-8622-ed0d1ac41c8d.png">

트리는 노드들이 나무 가지 처럼 연결된 비선형 계층적 자료구조이다.

- 트리는 트리내에 다른 하위 트리가 있고 그 하위 트리안에 다른 하위 트리가 있는 재귀적 자료구조 이기도 하다.
- 컴퓨터 구조가 트리의 대표적인 예시이다.
    
    <img width="685" alt="디렉토리 구조" src="https://user-images.githubusercontent.com/81874493/148179241-afa1d8cf-e55f-4a3e-b34c-b4eaae97a644.png">

<br>

<details>
<summary> 트리구조 용어 <- 클릭해주세요 </summary>

<div markdown="1">
    
<img width="683" alt="트리 구조 용어" src="https://user-images.githubusercontent.com/81874493/148179288-c52bb162-b226-435b-9fa9-e3bac9e03a87.png">

- Node
    - 트리를 구성하고 있는 기본 요소
    - 노드에는 키 또는 값과 하위 노드에 대한 포인터를 가진다.

<br>

- Edge
    - 노드와 노드 간의 연결선

<br>

- Root Node
    - 트리 구조에서 부모가 없는 최상위 노드

<br>

- Parent Node
    - 자식 노드를 가진 노드

<br>

- Child Node
    - 부모 노드의 하위 노드

<br>

- Sibling Node
    - 같은 부모를 가지는 노드

<br>

- Branch Node
    - 자식 노드가 하나 이상 가진 노드

<br>

- Leaf Node
    - 자식 노드가 없는 노드

<br>

- depth
    - 루트에서 어떤 노드까지의 간선의 수
    - 루트 노드의 깊이 : 0

<br>

- height
    - 어떤 노드에서 리프 노드까지 가장 긴 경로의 간선(Edge) 수

<br>

- Level
    - 루트에서 어떤 노드까지의 간선(Edge) 수

<br>

- Degree
    - 노드의 자식 수

<br>

- Path
    - 한 노드에서 다른 한 노드에 이르는 길 사이에 놓여있는 노드들의 순서

<br>

- Path Length
    - 해당 경로에 있는 총 노드의 수

<br>

- Size
    - 자신을 포함한 자손의 노드 수

<br>

- Width
    - 레벨에 있는 노드 수

<br>

- Breadth
    - 리프 노드의 수

<br>

- Distance
    - 두 노드 사이의 최단 경로에 있는 간선(Edge)의 수

<br>

- Order
    - 부모 노드가 가질 수 있는 최대 자식의 수

</div>
</details>

<br>

- 특징
    - 하나의 루트 노드와 0개 이상의 하위 트리로 구성되어 된다.
    - 데이터를 순차적으로 저장하지 않기 때문에 비선형 자료구조 이다.
    - 트리내에 또 다른 트리가 있는 재귀적 자료구조이다.
    - 단순 순환(Loop)을 갖지 않고, 연결된 무방향 그래프 구조이다.
    - 노드 간에 부모 자식 관계를 갖고 있는 계층형 자료구조이며 모든 자식 노드는 하나의 부모 노드만 갖는다.
    - 노드가 n개인 트리는 항상 n-1개의 간선(edge)을 갖는다.
    
    <br>

- 트리 종류
    
    편향 트리 (skew tree)
    
    - 모든 노드들이 자식을 하나만 가진 트리
    - 왼쪽 방향으로 자식을 하나씩만 가질 때 left skew tree, 오른쪽 방향으로 하나씩만 가질 때 right skew tree라고 함.
    
    <br>

    이진트리 (Binary Tree)
    
    - 각 노드의 차수(자식 노드)가 2 이하인 트리
    
    <br>

    이진 탐색 트리 (Binary Search Tree, BST)
    
    - 순서화된 이진 트리
    - 노드의 왼쪽 자식은 부모의 값보다 작은 값을 가져야 하며 노드의 오른쪽 자식은 부모의 값보다 큰 값을 가져야 함.
    
    <br>
    m 원 탐색 트리(m-way search tree)
    
    - 최대 m개의 서브 트리를 갖는 탐색 트리
    - 이진 탐색 트리의 확장된 형태로 높이를 줄이기 위해 사용함.
    
    <br>

    균형 트리 (Balanced Tree, B-Tree)
    
    - m원 탐색 트리에서 높이 균형을 유지하는 트리
    - height-balanced m-way tree라고도 함

<br>

- 트리 사용 사례
    
    계층 적 데이터 저장
    
    - 트리는 데이터를 계층 구조로 저장하는 데 사용됩니다.
    - 예를 들어 파일 및 폴더는 계층적 트리 형태로 저장됩니다.
    
    <br>

    효율적인 검색 속도
    
    - 효율적인 삽입, 삭제 및 검색을 위해 트리 구조를 사용합니다.
    
    <br>

    힙(Heap)
    
    - 힙도 트리로 된 자료 구조입니다.
    
    <br>

    데이터 베이스 인덱싱
    
    - 데이터베이스 인덱싱을 구현하는데 트리를 사용합니다.
    - 예) B-Tree, B+Tree, AVL-Tree..
    
    <br>
    Trie
    
    - 사전을 저장하는 데 사용되는 특별한 종류의 트리입니다

<br>

* * *

<br>

## 메모리 구조( Code, Data, Stack, Heap )

프로그램이 실행되기 위해서는 먼저 **프로그램이 메모리에 로드(load)** 되어야 한다.

또한, 프로그램에서 사용되는 **변수들을 저장할 메모리**도 필요하다.

<br>

따라서 **컴퓨터의 운영체제**는 프로그램의 실행을 위해 다양한 **메모리 공간**을 제공, 할당한다.

프로그램이 운영체제로부터 할당받는 대표적인 메모리 공간은 다음과 같다.

- Code 영역
- Data 영역 / BSS 영역
- Stack 영역
- Heap 영역

<br>

<메모리 구조>

<img width="634" alt="메모리 구조" src="https://user-images.githubusercontent.com/81874493/148179346-62a170ad-9868-4a4a-8857-75d4e9574f9b.png">

<br>

- 코드 영역
    - 코드 영역은 실행할 프로그램의 코드가 저장되는 영역
    - 텍스트 영역 이라고도 한다.
    - cpu는 코드 영역에 저장된 명령을 하나씩 가져가 처리하게 됨
    - 프로그램이 시작 → 종료 까지 메모리에 계속 남아있는다.

<br>

- 데이터 영역 , BSS(Block Started by Symbol) 영역
    - 데이터 영역은 전역 변수와 정적 변수가 저장되는 영역
        - 전역 변수 : 라이프 타임은 프로그램이 죽을때까지이며, 다른 파일에서도 해당 변수에 접근이 가능하다.
        - 정적 변수 : 라이프 타임은 전역변수와 마찬가지로 프로그램이 죽을때까지이며 static이라는 키워드가 반드시 붙고, 해당 변수가 선언된 scope에 따라서 접근 가능한 범위가 결정된다.
        
        ⇒ 공통점 라이프 타임이 프로그램이 죽을때 까지 유지된다.
        
        <br>

    - Data 영역은 **프로그램의 시작과 함께 할당**되며, 프로그램이 종료되면 소멸한다.
        
        ⇒ Data영역의 메모리의 크기는 컴파일 타임(Compile time)에 미리 결정된다.
        
        <br>

    - 전역변수와 정적변수를 선언할 때 **값을 초기화했으면 Data 영역**에 생성되고, **초기화하지 않았으면 BSS 영역**에 생성된다.
        
        ⇒ BSS 영역은 프로그램 실행을 시작하기 전에 **OS 커널에 의해** **0으로 자동 초기화**된다.
        
        ⇒ 전역변수와 정적변수를 프로그램 내에서 초기화하지 않아도 0으로 자동 초기화되는 이유가 이 때문
        
        <br>

- 힙(Heap) 영역
    - 메모리의 Heap 영역은 프로그래머가 직접 관리할 수 있는 (+ 관리 해야하는) 메모리 영역이다.

    <br>

    - 힙 영역은 선입선출(FIFO, First-In First-Out) 방식으로 가장 먼저 들어온 자료가 가장 먼저 인출 된다.
        
        ⇒ 이는 힙영역이 메모리의 낮은 주소에서 높은 주소의 방향으로 할당되기 때문이다.
        
        ⇒ 위의 그림에서 위(낮은 주소) 부터 차곡히 아래(높은 주소) 방향으로 자료가 쌓인다고 생각하면 된다.
        
        ⇒ 이렇게 쌓이다가 Heap 영역이 Stack 영역을 침범하는 경우 Heap Overflow 가 발생한다.
        
        <br>

    - 힙 영역에서 malloc() 또는 new 연산자를 통해 메모리를 할당하고, free() 또는 delete 연산자를 통해 메모리를 할당한다.
        
        ⇒ 메모리의 동적 할당
        
        - Data 영역과 Stack영역에 할당되는 메모리의 크기는 컴파일 타임에 미리 결정된다.
        - 하지만 힙 영역의 크기는 프로그램이 실행되는 도중 런타임(Run time)에 사용자가 직접 결정하게 된다.
            
            ⇒ 이렇게 런타임에 메모리를 할당 받는 것을 메모리의 동적할당(Dynamic allocation)이라고 한다.
            
            - malloc()
                
                ```c
                #include <stdlib.h>
                void *malloc(size_t size);
                ```
                
                - 인수로 할당 받고자 하는 메모리의 크기를 바이트 단위로 전달받는다.
                    
                    ⇒ 전달받은 메모리 크기에 맞는 아직 할당되지 않은 적당한 블록을 찾음
                    
                    ⇒ 이렇게 찾은 블록의 첫 번째 바이트를 가리키는 주소값을 반환, 블록이 없을때에는 null pointer 반환
                    
                    <br>

                - 주소값을 반환하기에 메모리에 접근하기 위해서는 포인터를 이용해야한다.
                
                <br>

            - free()
                
                ```c
                #include <stdlib.h>
                void free(void *ptr);
                ```
                
                - 인수로 해제하고자 하는 메모리 공간을 가리키는 포인터를 전달 받는다.
                
                <br>

                - 인수의 타입이 void형 포인트기 때문에 어떠한 타입의 포인터라도 인수로 전달 될 수 있다.
            
            <br>

- 스택(Stack) 영역
    - 스택 영역은 프로그램이 자동으로 사용하는 임시 메모리 영역이다.
    
    <br>

    - 함수 호출 시 생성되는 지역 변수와 매개 변수가 저장되는 영역이며, 함수 동작이 종료되고 복귀 주소로 돌아갈 시점에 사라진다.
    
    <br>
    
    - 이때 스택 영역에 저장되는 함수의 호출 정보를 스택 프레임(Stack Frame) 이라고 한다.
        - Stack Frame
            
            ⇒ EBP(Extended Base Pointer) 레지스터를 사용하여 스택 내의 로컬 변수, 파라미터, 복귀 주소에 접근하는 기법을 말한다.
            
            ⇒ 함수 동작 종료하고 복귀 주소로 돌아갈때 소멸됨
            
    <br>
    
        
    - 스택 영역에서는 push() 으로 자료를 저장, pop() 으로 데이터를 인출

    <br>
    
    - 스택 영역은 **후입 선출**(LIFO, Last-In First-Out) 의 방식으로, 가장 나중에 들어온 데이터가 가장 먼저 인출 된다.
        
        ⇒ 이는 스택 영역이 **메모리의 높은 주소에서 낮은 주소의 방향으로 쌓이기 때문**이다.
        
        ⇒ 위 의 그림으로 가장 아래(높은 주소) 부터 위(낮은 주소)로 데이터가 쌓인다고 생각하면 된다
        
        ⇒ 스택 영역에서 데이터가 쌓이다 Heap 영역을 침범하는 경우 Stack Overflow가 발생한다.

        <br>
        
        - 스택에 데이터가 들어갈수록 주소값이 작이지게 설계된 이유?
            - 스택 구조 위의 주소에는 운영 체제의 Kernel과 연결되어 있기 때문에 사용자가 함부로 영역을 침범하면 시스템에 치명적인 영향을 끼치게 되기 때문
